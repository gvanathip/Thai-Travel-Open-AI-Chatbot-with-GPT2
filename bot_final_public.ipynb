{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bot_final_public.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "mount_file_id": "1xOu9i9h-XKmUxaaJAWt21Oc0VRyumtzA",
      "authorship_tag": "ABX9TyNVm4QR2uBN0k7PNtgl9Y8y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvanathip/Thai-Travel-Open-AI-Chatbot-with-GPT2/blob/main/bot_final_public.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvmIMQ8WeDKL"
      },
      "outputs": [],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "# Imports\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n",
        "GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n",
        "using a masked language modeling (MLM) loss.\n",
        "\"\"\"\n",
        "\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from transformers import (\n",
        "    #MODEL_WITH_LM_HEAD_MAPPING,\n",
        "    MODEL_FOR_CAUSAL_LM_MAPPING,\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModelWithLMHead,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        "\n",
        "    AutoModelForCausalLM\n",
        ")\n",
        "\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter\n",
        "\n",
        "# Configs\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "#MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n",
        "MODEL_CONFIG_CLASSES = list(MODEL_FOR_CAUSAL_LM_MAPPING.keys())\n",
        "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
      ],
      "metadata": {
        "id": "sePjp3hoePEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Args():\n",
        "    def __init__(self):\n",
        "        #self.output_dir = 'output'\n",
        "        self.output_dir = '/content/drive/MyDrive/IS-DS/thaigpt-next-125m7_7'\n",
        "        self.model_type = 'gpt2'\n",
        "        # self.model_name_or_path = 'microsoft/DialoGPT-small'\n",
        "        # self.config_name = 'microsoft/DialoGPT-small'\n",
        "        # self.tokenizer_name = 'microsoft/DialoGPT-small'\n",
        "\n",
        "        self.model_name_or_path = 'wannaphong/thaigpt-next-125m'\n",
        "        self.config_name = 'wannaphong/thaigpt-next-125m'\n",
        "        self.tokenizer_name = 'wannaphong/thaigpt-next-125m'\n",
        "\n",
        "        self.cache_dir = 'cached'\n",
        "        #self.cache_dir = '/content/IS-DS/cached'\n",
        "        self.block_size = 512\n",
        "        self.do_train = True\n",
        "        self.do_eval = True\n",
        "        self.evaluate_during_training = False\n",
        "        self.per_gpu_train_batch_size = 4\n",
        "        self.per_gpu_eval_batch_size = 4\n",
        "        self.gradient_accumulation_steps = 1\n",
        "        self.learning_rate = 5e-5\n",
        "        self.weight_decay = 0.0\n",
        "        self.adam_epsilon = 1e-8\n",
        "        self.max_grad_norm = 1.0\n",
        "        self.num_train_epochs = 3\n",
        "        self.max_steps = -1\n",
        "        self.warmup_steps = 0\n",
        "        self.logging_steps = 1000\n",
        "        self.save_steps = 3500\n",
        "        self.save_total_limit = None\n",
        "        self.eval_all_checkpoints = False\n",
        "        self.no_cuda = False\n",
        "        #self.overwrite_output_dir = True\n",
        "        self.overwrite_output_dir = True\n",
        "        self.overwrite_cache = True\n",
        "        self.should_continue = False\n",
        "        self.seed = 42\n",
        "        self.local_rank = -1\n",
        "        self.fp16 = False\n",
        "        self.fp16_opt_level = 'O1'\n",
        "\n",
        "args = Args()"
      ],
      "metadata": {
        "id": "-YsK1NuGedf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path,)\n",
        "model = AutoModelForCausalLM.from_pretrained(args.output_dir)"
      ],
      "metadata": {
        "id": "ZiuKAZI2et5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyngrok"
      ],
      "metadata": {
        "id": "1ipHoe1-e33_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import threading\n",
        "\n",
        "from flask import Flask\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "YRiqkm6wC-4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install line-bot-sdk"
      ],
      "metadata": {
        "id": "n9KTHxYuFjQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ngrok http 5000"
      ],
      "metadata": {
        "id": "rCeQ_rXE0zLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trip = pd.read_csv('/content/drive/MyDrive/IS-DS/trip_planners.csv')\n",
        "trip.head()"
      ],
      "metadata": {
        "id": "dNzzBYEH79D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(trip.head(1)['region'])[0]"
      ],
      "metadata": {
        "id": "6WDOTk6UHSXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regions = list(set(trip.region))"
      ],
      "metadata": {
        "id": "nIYZ9keCKlL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pr = pd.DataFrame(columns=['region','province'])\n",
        "\n",
        "for r in regions:\n",
        "  pv = []\n",
        "  listToStr = ','.join([str(elem) for elem in list(trip[trip['region']==r]['plan'])])\n",
        "  s = listToStr.replace('[','')\n",
        "  s = s.replace(']','')\n",
        "  s = s.replace(\"'\",'')\n",
        "  s = s.replace('days','')\n",
        "  s = s.replace('day','')\n",
        "  s = s.replace('วัน','')\n",
        "  s = s.replace(',','')\n",
        "  s = s.strip()\n",
        "  print(r)\n",
        "  for i in s.split(' '):\n",
        "    if (len(i)==0)|(i.isnumeric()):\n",
        "      continue\n",
        "    else:\n",
        "      new_row = dict()\n",
        "      new_row['region'] = r\n",
        "      new_row['province'] = i\n",
        "\n",
        "      pr = pr.append(new_row, ignore_index=True)"
      ],
      "metadata": {
        "id": "GrEOYXAsJuU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pr"
      ],
      "metadata": {
        "id": "ryAz-5B8Nzvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "place = pd.read_csv('/content/drive/MyDrive/IS-DS/attraction.csv')\n",
        "place.head()"
      ],
      "metadata": {
        "id": "pAE90ywoZm1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "place = pd.merge(place,pr,on='province',how='left')"
      ],
      "metadata": {
        "id": "TEMAQHPx13L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "place"
      ],
      "metadata": {
        "id": "lWv50A2PKRF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#place = place.reset_index()"
      ],
      "metadata": {
        "id": "8C-AgQj6MaZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast"
      ],
      "metadata": {
        "id": "K9HqswBpvQ0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(trip.region)"
      ],
      "metadata": {
        "id": "l0tBPl0WAVZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(place.category)"
      ],
      "metadata": {
        "id": "Dtj64_KyRc3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pythainlp"
      ],
      "metadata": {
        "id": "9gKQNx36VQ1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "0WQy_BkMVPiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tpe = ' '.join([str(elem) for elem in list(set(place.type))])\n",
        "print(tpe)"
      ],
      "metadata": {
        "id": "JknelohaUyXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp.corpus import thai_stopwords\n",
        "stopwords = list(thai_stopwords())"
      ],
      "metadata": {
        "id": "OraU2c-zWFtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_word = list(set(word_tokenize(tpe)))"
      ],
      "metadata": {
        "id": "Uii_HxHsVWSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type_words = [\n",
        " 'กลางคืน',\n",
        " 'กลางแจ้ง',\n",
        " 'การแสดง',\n",
        " 'กิจกรรม',\n",
        " 'ชายหาด',\n",
        " 'ชุมชน',\n",
        " 'ช้อปปิ้ง',\n",
        " 'ดอกไม้',\n",
        " 'ดอย',\n",
        " 'ตลาด',\n",
        " 'ตลาดน้ำ',\n",
        " 'ถ้ำ',\n",
        " 'ถ้ำ',\n",
        " 'ทะเล',\n",
        " 'ทะเลสาบ',\n",
        " 'ทุ่ง',\n",
        " 'ท้องถิ่น',\n",
        " 'ธรรมชาติ',\n",
        " 'น้ำตก',\n",
        " 'น้ำพุ',\n",
        " 'ประวัติศาสตร์',\n",
        " 'ผจญภัย',\n",
        " 'ฝึกอบรม',\n",
        " 'พระราชดำริ',\n",
        " 'พระราชวัง',\n",
        " 'พิพิธภัณฑ์',\n",
        " 'พิพิธภัณฑ์สัตว์น้ำ',\n",
        " 'ภูเขา',\n",
        " 'มรดก',\n",
        " 'ลำคลอง',\n",
        " 'วัฒนธรรม',\n",
        " 'วัด',\n",
        " 'วิถีชีวิต',\n",
        " 'ศาสนา',\n",
        " 'ศิลปะ',\n",
        " 'สงครามโลก',\n",
        " 'สถานที่ศักดิ์สิทธิ์',\n",
        " 'สถานปฏิบัติธรรม',\n",
        " 'สถาปัตยกรรม',\n",
        " 'สนามกอล์ฟ',\n",
        " 'สปา',\n",
        " 'สวน',\n",
        " 'สวนสนุก',\n",
        " 'สวนสัตว์',\n",
        " 'สวนสาธารณะ',\n",
        " 'สัตว์',\n",
        " 'สัตว์ป่า',\n",
        " 'สุขภาพ',\n",
        " 'หมู่บ้าน',\n",
        " 'หมู่เกาะ',\n",
        " 'ห้องสมุด',\n",
        " 'องุ่น',\n",
        " 'อนุรักษ์',\n",
        " 'อนุสรณ์สถาน',\n",
        " 'อนุสาวรีย์',\n",
        " 'อาร์ต',\n",
        " 'อุทยานแห่งชาติ',\n",
        " 'อ่าว',\n",
        " 'เขื่อน',\n",
        " 'เบียร์',\n",
        " 'แกลเลอรี',\n",
        " 'แคมป์',\n",
        " 'แม่น้ำ',\n",
        " 'แหล่งท่องเที่ยว',\n",
        " 'โครงการหลวง',\n",
        " 'โบราณ',\n",
        " 'โบราณสถาน',\n",
        " 'โบสถ์',\n",
        " 'โรงงาน',\n",
        " 'โรงละคร',\n",
        " 'ไร่'\n",
        "]"
      ],
      "metadata": {
        "id": "dLvpPhUjRo3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region_words = ['เหนือ','กลาง','ใต้','อีสาน','ตะวันออก','ตะวันตก','ภาคเหนือ','ภาคกลาง','ภาคใต้','ภาคอีสาน','ภาคตะวันออก','ภาคตะวันตก']"
      ],
      "metadata": {
        "id": "OSdlTqB80YJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_words = ['พัก','โรงแรม','เดินทาง','รีวิว','ที่พัก','นอนไหน','นอนที่ไหน','พักไหน','พักที่ไหน','ไปยังไง']"
      ],
      "metadata": {
        "id": "zlTaDzIKkm_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "province_words = list(set(place.province))"
      ],
      "metadata": {
        "id": "zlkcSA2rblJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trip(df):\n",
        "  rnd_trip = random.choice(list(df['plan']))\n",
        "  tp = rnd_trip[1:-1]\n",
        "  tp = tp.replace(\"'\",'')\n",
        "  tp = tp.replace('days','วัน')\n",
        "  tp = tp.replace('day','วัน')\n",
        "  tp = tp.replace(\",\",' +')\n",
        "  print(tp)\n",
        "\n",
        "  df = df[df['plan']==rnd_trip]\n",
        "\n",
        "  rnd_place = random.choice(list(df['places']))\n",
        "  #print(rnd_place[1:-1])\n",
        "\n",
        "  df = df[df['places']==rnd_place]\n",
        "\n",
        "  plc_lnk = random.choice(list(df['place_link']))\n",
        "  plc_lnk = ast.literal_eval(plc_lnk)\n",
        "\n",
        "  rg = list(df['region'])[0]\n",
        "  \n",
        "  pc_v = ''\n",
        "  pc_k = ''\n",
        "  for pc in plc_lnk:\n",
        "    pc_k = pc_k+pc+','\n",
        "    pc_v = pc_v+pc+'\\n'+plc_lnk[pc]+'\\n\\n'\n",
        "\n",
        "  text_y = pc_v+'\\n\\n'+tp+'\\n'+rg+'\\n'+pc_k\n",
        "  print('print test : ',str(text_y))\n",
        "\n",
        "  return str(text_y)"
      ],
      "metadata": {
        "id": "4nPtIQaTBg7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trip = trip.drop_duplicates()\n",
        "place = place.drop_duplicates()"
      ],
      "metadata": {
        "id": "m8_nwEQYEHk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp.spell import *"
      ],
      "metadata": {
        "id": "9EXTxUTs5iJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp import correct"
      ],
      "metadata": {
        "id": "NRytgu0I8b22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp import word_vector\n",
        "model_ = word_vector.get_model()"
      ],
      "metadata": {
        "id": "DlXYnNFpUdyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp.util import normalize"
      ],
      "metadata": {
        "id": "bVpnSbkGXgrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bos = pd.read_csv('/content/drive/MyDrive/IS-DS/bos.csv')"
      ],
      "metadata": {
        "id": "5e8O-kdBjDlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gevent"
      ],
      "metadata": {
        "id": "Ff99JGQTzyyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googlesearch import search\n",
        "from transformers.utils.dummy_pt_objects import TextDataset\n",
        "from flask import Flask, request\n",
        "from linebot.models import *\n",
        "from linebot import *\n",
        "import json\n",
        "import csv\n",
        "\n",
        "from gevent.pywsgi import WSGIServer"
      ],
      "metadata": {
        "id": "spxtrzw3zedX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "region_history = []\n",
        "type_history = []\n",
        "province_history = []\n",
        "\n",
        "\n",
        "#step = 0\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "line_bot_api = LineBotApi('xxx')\n",
        "handler = WebhookHandler('xxx')\n",
        "\n",
        "@app.route(\"/callback\", methods=['POST'])\n",
        "def callback():\n",
        "    body = request.get_data(as_text=True)\n",
        "    # print(body)\n",
        "    req = request.get_json(silent=True, force=True)\n",
        "    # req = request.get_json(force=False,cache=False)\n",
        "    intent = req[\"queryResult\"][\"intent\"][\"displayName\"]\n",
        "    text = req['originalDetectIntentRequest']['payload']['data']['message']['text']\n",
        "    msgType = req['originalDetectIntentRequest']['payload']['data'][\"message\"][\"type\"]\n",
        "    reply_token = req['originalDetectIntentRequest']['payload']['data']['replyToken']\n",
        "    id = req['originalDetectIntentRequest']['payload']['data']['source']['userId']\n",
        "    disname = line_bot_api.get_profile(id).display_name\n",
        "\n",
        "\n",
        "    chat_history.append(text)\n",
        "\n",
        "    print('id = ' + id)\n",
        "    print('name = ' + disname)\n",
        "    print('text = ' + text)\n",
        "    print('intent = ' + intent)\n",
        "    print('reply_token = ' + reply_token)\n",
        "\n",
        "\n",
        "\n",
        "    reply(intent,text,reply_token,id,disname)\n",
        "\n",
        "    return 'OK'\n",
        "\n",
        "\n",
        "def reply(intent,text,reply_token,id,disname):\n",
        "\n",
        "    # if intent == 'Default Fallback Intent':\n",
        "    text_token = set(word_tokenize(text))\n",
        "    found_type = text_token.intersection(set(type_words))\n",
        "    found_region = text_token.intersection(set(region_words))\n",
        "    found_province = text_token.intersection(set(province_words))\n",
        "    found_search = text_token.intersection(set(search_words))\n",
        "\n",
        "    if os.path.isfile('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv'):\n",
        "      with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([disname,text])\n",
        "        user_type = 'existing user'\n",
        "        print('new_user:',user_type)\n",
        "    # else:\n",
        "    #   with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','w') as f:\n",
        "    #     writer = csv.writer(f)\n",
        "    #     writer.writerow(['display_name','text']) \n",
        "    #     writer.writerow([disname,text])      \n",
        "    #     user_type = 'new user'\n",
        "    #     print('new_user:',user_type)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      if len(chat_history) > 1:\n",
        "\n",
        "          if len(list(found_search)) > 0:\n",
        "            y = ''\n",
        "            for j in search(text, num=5, stop=5, pause=2):\n",
        "              y = y+'\\n'+j\n",
        "            chat_history.append(y)\n",
        "            with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','a') as f:\n",
        "              writer = csv.writer(f)\n",
        "              writer.writerow(['bot',y])\n",
        "            text_message = TextSendMessage(text=y)\n",
        "            line_bot_api.reply_message(reply_token,text_message)   \n",
        "\n",
        "          elif len(list(found_region))*len(list(found_type))*len(list(found_province)) > 0:\n",
        "            print('region :',found_region)\n",
        "            print('type :',found_type)\n",
        "            print('province :',found_province)\n",
        "            its_type = list(found_type)\n",
        "            itss_type = '|'.join([str(elem) for elem in its_type])\n",
        "            \n",
        "            type_history.append(itss_type)\n",
        "\n",
        "            if type_history[-1] == 'ทะเล':\n",
        "              place_df = place[place['place'].str.contains('ทะเลสาบ')==False]\n",
        "            else:\n",
        "              place_df = place.copy()\n",
        "              place_df = place_df.drop_duplicates()\n",
        "            place_df = place_df[place_df['place'].str.contains(type_history[-1])==True]\n",
        "\n",
        "            its_province = list(found_province)\n",
        "            itss_province = '|'.join([str(elem) for elem in its_province])\n",
        "            \n",
        "            province_history.append(itss_province)\n",
        "\n",
        "            place_df = place_df[place_df['province'].str.contains(province_history[-1])==True]\n",
        "\n",
        "            plc_lnk = random.choices(list(place_df['link']), k=3)\n",
        "\n",
        "            rnd_place_df = place[place['link'].isin(plc_lnk)]\n",
        "            df = rnd_place_df.reset_index()  # make sure indexes pair with number of rows\n",
        "            df = df.drop_duplicates()\n",
        "            y = ''\n",
        "            for index, row in df.iterrows():\n",
        "              y = y+'\\n'+row['place']+'\\n'+row['link']\n",
        "\n",
        "            chat_history.append(y)\n",
        "            with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','a') as f:\n",
        "              writer = csv.writer(f)\n",
        "              writer.writerow(['bot',y])          \n",
        "            text_message = TextSendMessage(text=y)\n",
        "            line_bot_api.reply_message(reply_token,text_message)\n",
        "\n",
        "          elif len(list(found_type))*len(list(found_province)) > 0:\n",
        "            print('type :',found_type)\n",
        "            print('province :',found_province)\n",
        "            its_type = list(found_type)\n",
        "            itss_type = '|'.join([str(elem) for elem in its_type])\n",
        "            \n",
        "            type_history.append(itss_type)\n",
        "\n",
        "            if type_history[-1] == 'ทะเล':\n",
        "              place_df = place[place['place'].str.contains('ทะเลสาบ')==False]\n",
        "            else:\n",
        "              place_df = place.copy()\n",
        "              place_df = place_df.drop_duplicates()\n",
        "            place_df = place_df[place_df['place'].str.contains(type_history[-1])==True]\n",
        "\n",
        "            its_province = list(found_province)\n",
        "            itss_province = '|'.join([str(elem) for elem in its_province])\n",
        "            \n",
        "            province_history.append(itss_province)\n",
        "\n",
        "            place_df = place_df[place_df['province'].str.contains(province_history[-1])==True]\n",
        "\n",
        "            plc_lnk = random.choices(list(place_df['link']), k=3)\n",
        "\n",
        "            rnd_place_df = place[place['link'].isin(plc_lnk)]\n",
        "            df = rnd_place_df.reset_index()  # make sure indexes pair with number of rows\n",
        "            df = df.drop_duplicates()\n",
        "            y = ''\n",
        "            for index, row in df.iterrows():\n",
        "              y = y+'\\n'+row['place']+'\\n'+row['link']\n",
        "\n",
        "            chat_history.append(y)\n",
        "            with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','a') as f:\n",
        "              writer = csv.writer(f)\n",
        "              writer.writerow(['bot',y])          \n",
        "            text_message = TextSendMessage(text=y)\n",
        "            line_bot_api.reply_message(reply_token,text_message)\n",
        "\n",
        "          elif len(list(found_type))*len(list(found_region)) > 0:\n",
        "            print('type :',found_type)\n",
        "            print('region :',found_region)\n",
        "            its_type = list(found_type)\n",
        "            itss_type = '|'.join([str(elem) for elem in its_type])\n",
        "            \n",
        "            type_history.append(itss_type)\n",
        "\n",
        "            if type_history[-1] == 'ทะเล':\n",
        "              place_df = place[place['place'].str.contains('ทะเลสาบ')==False]\n",
        "            else:\n",
        "              place_df = place.copy()\n",
        "              place_df = place_df.drop_duplicates()\n",
        "            place_df = place_df[place_df['place'].str.contains(type_history[-1])==True]\n",
        "\n",
        "            its_region = list(found_region)\n",
        "            its_region = list(map(lambda x: x.replace('ภาค',''),its_region))\n",
        "            its_region = ['ภาค' + sub for sub in its_region]\n",
        "            itss_region = '|'.join([str(elem) for elem in its_region])\n",
        "            itss_region = itss_region.replace('อีสาน','ตะวันออกเฉียงเหนือ')\n",
        "            \n",
        "            region_history.append(itss_region)\n",
        "\n",
        "            place_df = place_df[place_df['region'].str.contains(region_history[-1])==True]\n",
        "\n",
        "            plc_lnk = random.choices(list(place_df['link']), k=3)\n",
        "\n",
        "            rnd_place_df = place[place['link'].isin(plc_lnk)]\n",
        "            df = rnd_place_df.reset_index()  # make sure indexes pair with number of rows\n",
        "            df = df.drop_duplicates()\n",
        "            y = ''\n",
        "            for index, row in df.iterrows():\n",
        "              y = y+'\\n'+row['place']+'\\n'+row['link']\n",
        "\n",
        "            chat_history.append(y)\n",
        "            with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','a') as f:\n",
        "              writer = csv.writer(f)\n",
        "              writer.writerow(['bot',y])          \n",
        "            text_message = TextSendMessage(text=y)\n",
        "            line_bot_api.reply_message(reply_token,text_message)\n",
        "\n",
        "          elif len(list(found_region))>0:\n",
        "            its = list(found_region)\n",
        "            its = list(map(lambda x: x.replace('ภาค',''),its))\n",
        "            its = ['ภาค' + sub for sub in its]\n",
        "            itss = '|'.join([str(elem) for elem in its])\n",
        "            itss = itss.replace('อีสาน','ตะวันออกเฉียงเหนือ')\n",
        "            \n",
        "            region_history.append(itss)\n",
        "\n",
        "            trip_df = trip[trip['region'].str.contains(itss)==True]\n",
        "            y = print_trip(trip_df)\n",
        "\n",
        "            chat_history.append(y)\n",
        "            with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','a') as f:\n",
        "              writer = csv.writer(f)\n",
        "              writer.writerow(['bot',y])          \n",
        "            text_message = TextSendMessage(text=y)\n",
        "            line_bot_api.reply_message(reply_token,text_message)\n",
        "\n",
        "\n",
        "\n",
        "          elif len(list(found_type))>0:\n",
        "            its = list(found_type)\n",
        "            itss = '|'.join([str(elem) for elem in its])\n",
        "            \n",
        "            type_history.append(itss)\n",
        "\n",
        "            if type_history[-1] == 'ทะเล':\n",
        "              place_df = place[place['place'].str.contains('ทะเลสาบ')==False]\n",
        "            else:\n",
        "              place_df = place.copy()\n",
        "              place_df = place_df.drop_duplicates()\n",
        "            place_df = place_df[place_df['place'].str.contains(type_history[-1])==True]\n",
        "\n",
        "            plc_lnk = random.choices(list(place_df['link']), k=3)\n",
        "\n",
        "            rnd_place_df = place[place['link'].isin(plc_lnk)]\n",
        "            df = rnd_place_df.reset_index()  # make sure indexes pair with number of rows\n",
        "            df = df.drop_duplicates()\n",
        "            y = ''\n",
        "            for index, row in df.iterrows():\n",
        "              y = y+'\\n'+row['place']+'\\n'+row['link']\n",
        "                # print(row['c1'], row['c2'])\n",
        "            \n",
        "            chat_history.append(y)\n",
        "            with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','a') as f:\n",
        "              writer = csv.writer(f)\n",
        "              writer.writerow(['bot',y])          \n",
        "            text_message = TextSendMessage(text=y)\n",
        "            line_bot_api.reply_message(reply_token,text_message)\n",
        "\n",
        "          elif len(list(found_province))>0:\n",
        "            its = list(found_province)\n",
        "            itss = '|'.join([str(elem) for elem in its])\n",
        "            \n",
        "            province_history.append(itss)\n",
        "\n",
        "            place_df = place.copy()\n",
        "            place_df = place_df[place_df['province'].str.contains(province_history[-1])==True]\n",
        "\n",
        "            plc_lnk = random.choices(list(place_df['link']), k=3)\n",
        "\n",
        "            rnd_place_df = place[place['link'].isin(plc_lnk)]\n",
        "            df = rnd_place_df.reset_index()  # make sure indexes pair with number of rows\n",
        "            df = df.drop_duplicates()\n",
        "            y = ''\n",
        "            for index, row in df.iterrows():\n",
        "              y = y+'\\n'+row['place']+'\\n'+row['link']\n",
        "                # print(row['c1'], row['c2'])          \n",
        "\n",
        "            # trip_df = trip[trip['plan'].str.contains(province_history[-1])==True]\n",
        "            # y = print_trip(trip_df)\n",
        "\n",
        "            chat_history.append(y)\n",
        "            with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','a') as f:\n",
        "              writer = csv.writer(f)\n",
        "              writer.writerow(['bot',y])          \n",
        "            text_message = TextSendMessage(text=y)\n",
        "            line_bot_api.reply_message(reply_token,text_message)   \n",
        "\n",
        "\n",
        "          elif ('เที่ยว' in text) or ('ไปไหนดี') in text:\n",
        "  \n",
        "            y = print_trip(trip)\n",
        "\n",
        "            # print(pics)\n",
        "            chat_history.append(y)\n",
        "            with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','a') as f:\n",
        "              writer = csv.writer(f)\n",
        "              writer.writerow(['bot',y])          \n",
        "            text_message = TextSendMessage(text=y)\n",
        "            line_bot_api.reply_message(reply_token,text_message)   \n",
        "\n",
        "  \n",
        "\n",
        "          elif text in ['ไม่เอา','เอาใหม่']:\n",
        "            y = chat_history[-2]\n",
        "            with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','a') as f:\n",
        "              writer = csv.writer(f)\n",
        "              writer.writerow(['bot',y])          \n",
        "            text_message = TextSendMessage(text=y)\n",
        "            line_bot_api.reply_message(reply_token,text_message)\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "          else:\n",
        "            # if chat_history[-2] > 0:\n",
        "            #   try:\n",
        "            #     x = model_.most_similar_cosmul(positive=[normalize(text)])[0][0]\n",
        "            #   except:\n",
        "            #     x = random.choice(list(bos['0']))\n",
        "            # else:\n",
        "            x = normalize(text)\n",
        "            \n",
        "            new_user_input_ids = tokenizer.encode(x + tokenizer.eos_token, return_tensors='pt')\n",
        "            #bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "            try:\n",
        "              bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1)\n",
        "              #bot_input_ids = new_user_input_ids\n",
        "\n",
        "              chat_history_ids = model.generate(\n",
        "                  bot_input_ids, max_length=100,\n",
        "                  pad_token_id=tokenizer.eos_token_id,\n",
        "                  top_p=0.92, top_k = 50\n",
        "                )\n",
        "            except:\n",
        "              bot_input_ids = new_user_input_ids\n",
        "              chat_history_ids = model.generate(\n",
        "                  bot_input_ids, max_length=100,\n",
        "                  pad_token_id=tokenizer.eos_token_id,\n",
        "                  top_p=0.92, top_k = 50\n",
        "                )\n",
        "        \n",
        "            y = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "            while True:\n",
        "              if chat_history[-10:].count(y)>0:\n",
        "                try:\n",
        "                  # x = model_.most_similar_cosmul(positive=[normalize(text)])[0][0]\n",
        "                  x = model_.most_similar_cosmul(positive=[x])[0][0]\n",
        "                except:\n",
        "                  x = random.choice(list(bos['0']))\n",
        "                new_user_input_ids = tokenizer.encode(x + tokenizer.eos_token, return_tensors='pt')\n",
        "                #bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "                try:\n",
        "                  bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1)\n",
        "                  #bot_input_ids = new_user_input_ids\n",
        "\n",
        "                  chat_history_ids = model.generate(\n",
        "                      bot_input_ids, max_length=300,\n",
        "                      pad_token_id=tokenizer.eos_token_id,\n",
        "                      top_p=0.92, top_k = 50\n",
        "                    )\n",
        "                except:\n",
        "                  bot_input_ids = new_user_input_ids\n",
        "                  chat_history_ids = model.generate(\n",
        "                      bot_input_ids, max_length=300,\n",
        "                      pad_token_id=tokenizer.eos_token_id,\n",
        "                      top_p=0.92, top_k = 50\n",
        "                    )\n",
        "                y = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "              else:\n",
        "                break\n",
        "\n",
        "              \n",
        "\n",
        "          \n",
        "\n",
        "            y = y.replace('name',disname)\n",
        "            y = y.replace('มึง',disname)\n",
        "            y = y.replace('ภู ',disname)\n",
        "            y = y.replace('อีเชี่ย','')\n",
        "            y = y.replace('�','')\n",
        "            y = y.replace('ครูลูกตาล','')\n",
        "            y = y.replace('ทิม','')\n",
        "            y = correct(y)\n",
        "\n",
        "            if len(y) < 1:\n",
        "              y = 'อะไรนะ เราไม่เข้าใจ'\n",
        "\n",
        "            chat_history.append(y)\n",
        "            with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','a') as f:\n",
        "              writer = csv.writer(f)\n",
        "              writer.writerow(['bot',y])\n",
        "\n",
        "            text_message = TextSendMessage(text=y)\n",
        "            line_bot_api.reply_message(reply_token,text_message)\n",
        "\n",
        "\n",
        "      if len(chat_history) == 1 or user_type == 'new user':\n",
        "        welcome_back = ['สวัสดี','หวัดดี','ดีจ้า']\n",
        "        welcome_back.append(text)\n",
        "        y = random.choice(welcome_back)\n",
        "        y = y+' เดี๋ยวเราช่วยหาข้อมูลที่เที่ยว ที่พัก รีวิว ให้เอง คุยกับเราได้เลย'\n",
        "        chat_history.append(y)\n",
        "        with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','a') as f:\n",
        "          writer = csv.writer(f)\n",
        "          writer.writerow(['bot',y])      \n",
        "        text_message = TextSendMessage(text=y)\n",
        "        line_bot_api.reply_message(reply_token,text_message)\n",
        "\n",
        "      print('reply = '+ y)\n",
        "\n",
        "    else:\n",
        "      with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['display_name','text']) \n",
        "        writer.writerow([disname,text])      \n",
        "        user_type = 'new user'\n",
        "        print('new_user:',user_type)\n",
        "\n",
        "        welcome_back = ['สวัสดี','หวัดดี','ดีจ้า']\n",
        "        welcome_back.append(text)\n",
        "        y = random.choice(welcome_back)\n",
        "        y = y+' เดี๋ยวเราช่วยหาข้อมูลที่เที่ยว ที่พัก รีวิว ให้เอง คุยกับเราได้เลย'\n",
        "        chat_history.append(y)\n",
        "        with open('/content/drive/MyDrive/IS-DS/chat_history/'+disname+'.csv','a') as f:\n",
        "          writer = csv.writer(f)\n",
        "          writer.writerow(['bot',y])      \n",
        "        text_message = TextSendMessage(text=y)\n",
        "        line_bot_api.reply_message(reply_token,text_message)\n",
        "\n",
        "        print('reply = '+ y)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Debug/Development\n",
        "    # app.run(debug=True, host=\"0.0.0.0\", port=\"5000\")\n",
        "    # Production\n",
        "    http_server = WSGIServer(('', 5000), app)\n",
        "    http_server.serve_forever()"
      ],
      "metadata": {
        "id": "mPrLfptdCl7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LTM1yHepKSxu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}